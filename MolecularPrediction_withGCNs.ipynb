{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741de375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spektral in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (1.0.8)\n",
      "Requirement already satisfied: networkx in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (2.5)\n",
      "Requirement already satisfied: numpy<1.20 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (1.19.5)\n",
      "Requirement already satisfied: lxml in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (4.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (4.59.0)\n",
      "Requirement already satisfied: pandas in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (0.24.1)\n",
      "Requirement already satisfied: scipy in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (1.6.2)\n",
      "Requirement already satisfied: joblib in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (1.0.1)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (2.6.0)\n",
      "Requirement already satisfied: requests in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from spektral) (2.25.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (1.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (1.39.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (5.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (3.17.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (0.13.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (0.36.2)\n",
      "Requirement already satisfied: keras~=2.6 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (2.6.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.1.0->spektral) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from requests->spektral) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from requests->spektral) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from requests->spektral) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from requests->spektral) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from networkx->spektral) (5.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from pandas->spektral) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from pandas->spektral) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sidneyarcidiacono/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->spektral) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment & run me to install Spektral! \n",
    "# !pip install spektral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34742502",
   "metadata": {},
   "source": [
    "**The QM9 Dataset**\n",
    "\n",
    "The QM9 dataset is a benchmark small-molecule dataset comprised of labeled nodes (of which there are five types: H, C, N, O, F, representing their respective atoms on the periodic table, Hydrogen, Carbon, Nitrogen, Oxygen, and Fluorine) and edges which represent chemical bonds. \n",
    "\n",
    "Node features represent our atoms' chemical properties and include: \n",
    "\n",
    "- Position of the atom in x, y and z dimensions\n",
    "- The atomic number of the atom, one-hot encoded\n",
    "- The atomic charge\n",
    "- The mass difference from the monoisotope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41181584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 133885/133885 [02:34<00:00, 864.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: QM9(n_graphs=133885)\n",
      "First graph: Graph(n_nodes=5, n_node_features=10, n_edge_features=4, n_labels=19)\n",
      "Number of graphs: 133885\n"
     ]
    }
   ],
   "source": [
    "# Import and read in our dataset\n",
    "from spektral.datasets.qm9 import QM9\n",
    "\n",
    "# Instantiate our dataset\n",
    "dataset = QM9()\n",
    "\n",
    "# Check out our features:\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"First graph: {dataset[0]}\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdeb2a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph labels: [ 3.29932000e+00  1.02987000e+00  9.70160000e-01  5.52060000e+00\n",
      "  7.93700000e+01 -2.77600000e-01  3.86000000e-02  3.16200000e-01\n",
      "  1.29977970e+03  1.71140000e-01 -4.03187169e+02 -4.03178075e+02\n",
      " -4.03177131e+02 -4.03221255e+02  3.47780000e+01 -1.95050003e+03\n",
      " -1.96256891e+03 -1.97383081e+03 -1.81564082e+03]\n",
      "First 10 node labels: [[ 0.      1.      0.      0.      0.     -0.2233  1.5468 -0.0164  0.\n",
      "   0.    ]\n",
      " [ 0.      1.      0.      0.      0.      0.0687  0.0474 -0.0079  0.\n",
      "   0.    ]\n",
      " [ 0.      0.      0.      1.      0.     -1.157  -0.6947  0.0414  0.\n",
      "   0.    ]\n",
      " [ 0.      1.      0.      0.      0.      0.9169 -0.434  -1.2068  0.\n",
      "   0.    ]\n",
      " [ 0.      1.      0.      0.      0.      1.4848 -1.775  -0.7332  0.\n",
      "   0.    ]\n",
      " [ 0.      1.      0.      0.      0.      1.9259 -1.4485  0.7173  0.\n",
      "   0.    ]\n",
      " [ 0.      1.      0.      0.      0.      0.8673 -0.4236  1.2363  0.\n",
      "   0.    ]\n",
      " [ 0.      1.      0.      0.      0.      2.0745 -2.625   1.5671  0.\n",
      "   0.    ]\n",
      " [ 0.      0.      1.      0.      0.      2.1918 -3.5597  2.2375  0.\n",
      "   0.    ]\n",
      " [ 1.      0.      0.      0.      0.      0.7003  2.134   0.      0.\n",
      "   0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few node labels, the graph labels, and the node features to see how they're represented\n",
    "# Our graph label is our 19-dimensional label for regression\n",
    "print(f\"Graph labels: {dataset[0].y}\")\n",
    "# Our node labels represent our atoms\n",
    "print(f\"First 10 node labels: {dataset[0].x[0:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b520472",
   "metadata": {},
   "source": [
    "We're going to use a crystal convolutional layer, similar to the approach in [this paper](https://arxiv.org/abs/1710.10324) which also uses QM9 as its benchmark dataset. \n",
    "\n",
    "The goal is to predict chemical properties of molecules. We're going to maintain explanations at a high level, for the purpose of this walkthrough, to get a handle on using existing libraries to implement various types of GCNs. \n",
    "\n",
    "Spektral is built on top of Tensorflow & Keras functionality, making it extraordinarily intuitive to implement for engineers already working with these tools. Another great alternative for implementation of Graph Neural Networks is [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/index.html), which I've provided an example for [here](https://github.com/sidneyarcidiacono/graph-convolutional-networks/blob/main/notebooks/PROTEINS_Embedding.ipynb) if you're interested in seeing how the implementation differs from Spektral. \n",
    "\n",
    "Spektral is, in my opinion, only more convenient for quick prototyping or proof-of-concept work, as it's easier to install with pip without the need to deal with additional dependencies, GPU setup, and so on.\n",
    "\n",
    "// later on talk about the implications of being able to do this for material science, chemistry, biology, etc: What's important to take away is the implication of being able to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8812ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to do a slightly messy train/test split:\n",
    "import numpy as np\n",
    "\n",
    "np.random.shuffle(dataset)\n",
    "split = int(0.8 * len(dataset))\n",
    "data_train, data_test = dataset[:split], dataset[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42300506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spektral is built on top of Keras, so we can use the Keras functional API to build a model that first embeds,\n",
    "# then sums the nodes together (global pooling), then classifies the result with a dense softmax layer\n",
    "\n",
    "# First, let's import the necessary layers:\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c50b3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can use model subclassing to define our model:\n",
    "\n",
    "class MoleculePredictor(Model):\n",
    "  \n",
    "    def __init__(self, n_hidden, n_labels):\n",
    "        super().__init__()\n",
    "        # Define our GCN layer with our n_hidden layers\n",
    "        self.graph_conv = GCNConv(n_hidden)\n",
    "        # Define our dropout layer, initialize dropout freq. to .5 (50%)\n",
    "        self.dropout = Dropout(0.5)\n",
    "        # Define our Dense layer, with softmax activation function\n",
    "        self.dense = Dense(n_labels, 'softmax')\n",
    "    \n",
    "    def call(self, inputs, mask=None):\n",
    "        x, a, y = inputs\n",
    "        print(f\"Shape of X: {x.shape}\")\n",
    "\n",
    "        # Update node features\n",
    "        x = tf.matmul(x, self.weights)\n",
    "\n",
    "        return self.propagate(x=x, a=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c5a564bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model for training\n",
    "model = MoleculePredictor(32, dataset.n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b6390e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with our optimizer (adam) and loss function\n",
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fa216a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the trick - we can't just call Keras' fit() method on this model.\n",
    "# Instead, we have to use Loaders, which Spektral walks us through. Loaders create mini-batches by iterating over the graph\n",
    "# Since we're using Spektral for an experiment, for our first trial we'll use the recommended loader in the getting started tutorial\n",
    "\n",
    "# TODO: read up on modes and try other loaders later\n",
    "from spektral.data import BatchLoader\n",
    "\n",
    "loader = BatchLoader(data_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b6ab6fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (32, 29, 10)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[1] ndims must be >= 2: 1 [Op:BatchMatMulV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-d3ba70c2f22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# But we do need to specify the steps_per_epoch parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m       model.distribute_strategy.run(\n\u001b[0m\u001b[1;32m    802\u001b[0m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    800\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m       model.distribute_strategy.run(\n\u001b[0;32m--> 802\u001b[0;31m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-00f037a4560d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Update node features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3605\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[1;32m   3606\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m         return gen_math_ops.batch_mat_mul_v2(\n\u001b[0m\u001b[1;32m   3608\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[1;32m   3609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1507\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: In[1] ndims must be >= 2: 1 [Op:BatchMatMulV2]"
     ]
    }
   ],
   "source": [
    "# Now we can train! We don't need to specify a batch size, since our loader is basically a generator\n",
    "# But we do need to specify the steps_per_epoch parameter\n",
    "\n",
    "model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38122ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
